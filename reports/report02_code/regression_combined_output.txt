
Crossvalidation fold: 1/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 1  2  5  7  8  9 11 12 13 17 18 19 20 21 22 24 25 26 28 32 35 37 40 41 42
 43 44 51 53]
word_freq_all: [ 0.02361459]
word_freq_3d: [ 0.01048329]
word_freq_remove: [-0.0462028]
word_freq_order: [ 0.16304368]
word_freq_mail: [ 0.03223481]
word_freq_receive: [ 0.06997759]
word_freq_people: [ 0.04622982]
word_freq_report: [ 0.13915457]
word_freq_addresses: [ 0.06239]
word_freq_you: [-0.05034154]
word_freq_credit: [ 0.03352973]
word_freq_your: [-0.04316472]
word_freq_font: [ 0.1108601]
word_freq_000: [ 0.06264135]
word_freq_money: [ 0.03809978]
word_freq_hpl: [-0.01441286]
word_freq_george: [-0.06324418]
word_freq_650: [-0.02609537]
word_freq_labs: [-0.02555468]
word_freq_415: [ 0.01674192]
word_freq_1999: [ 0.04148551]
word_freq_pm: [-0.02281186]
word_freq_meeting: [-0.03554663]
word_freq_original: [-0.02281493]
word_freq_project: [-0.02485536]
word_freq_re: [-0.04674477]
word_freq_edu: [-0.02431759]
char_freq_$: [ 0.09282113]
capital_run_length_average: [ 0.09412232]
Cross validation fold 1/10
Train indices: [   0    2    3 ..., 4598 4599 4600]
Test indices: [   1   14   29   36   50   62   70   79   88   90  132  134  136  144  163
  176  193  219  224  254  287  313  318  322  328  351  354  358  385  396
  406  414  421  423  431  440  459  464  482  486  498  505  506  513  519
  537  547  548  549  554  580  583  603  606  637  640  663  675  681  701
  706  714  746  749  760  775  776  780  787  788  789  792  794  798  809
  815  828  833  834  837  843  845  856  867  869  882  885  896  934  939
  941  946  952  964  979  988  994 1010 1015 1027 1034 1044 1045 1057 1062
 1070 1076 1108 1114 1136 1157 1175 1181 1183 1186 1187 1195 1213 1219 1229
 1231 1241 1254 1268 1269 1284 1298 1303 1305 1308 1314 1338 1340 1348 1356
 1362 1372 1376 1378 1382 1384 1393 1395 1403 1411 1415 1431 1438 1440 1456
 1459 1460 1466 1469 1475 1478 1497 1512 1513 1515 1518 1580 1586 1593 1594
 1616 1629 1634 1644 1646 1651 1684 1706 1712 1715 1718 1753 1760 1769 1774
 1786 1804 1814 1823 1831 1834 1835 1838 1845 1847 1848 1855 1862 1881 1884
 1887 1889 1895 1940 1945 1955 1970 1972 1974 1993 1999 2016 2021 2022 2052
 2054 2076 2084 2090 2096 2099 2105 2122 2138 2184 2214 2216 2224 2226 2229
 2238 2251 2261 2264 2268 2270 2273 2298 2319 2349 2353 2354 2360 2371 2372
 2394 2408 2446 2456 2458 2490 2491 2497 2530 2536 2540 2543 2553 2556 2565
 2572 2573 2597 2607 2608 2612 2616 2620 2640 2646 2672 2682 2686 2690 2691
 2730 2739 2762 2769 2796 2805 2819 2832 2833 2844 2845 2848 2862 2866 2891
 2910 2912 2921 2933 2940 2949 2952 2954 2957 2969 2975 2996 2998 3001 3006
 3015 3017 3018 3023 3024 3029 3035 3042 3044 3053 3058 3080 3085 3097 3100
 3115 3123 3124 3132 3136 3139 3141 3156 3177 3183 3189 3198 3203 3204 3220
 3225 3230 3249 3269 3282 3310 3325 3338 3342 3354 3377 3380 3381 3387 3401
 3408 3416 3417 3424 3432 3437 3451 3488 3494 3511 3512 3516 3521 3539 3547
 3557 3558 3559 3575 3576 3605 3614 3617 3624 3625 3643 3663 3670 3706 3712
 3720 3744 3753 3758 3764 3777 3779 3783 3787 3798 3804 3833 3851 3861 3868
 3891 3893 3902 3922 3924 3958 3965 3968 3971 3974 3978 4001 4003 4005 4018
 4050 4054 4056 4059 4060 4078 4083 4088 4089 4092 4103 4112 4119 4125 4138
 4155 4162 4175 4192 4208 4214 4226 4255 4258 4261 4269 4270 4272 4277 4278
 4285 4289 4317 4323 4353 4354 4356 4363 4385 4397 4403 4404 4406 4413 4417
 4428 4431 4463 4490 4502 4511 4514 4530 4562 4574 4590]
Features no: 29

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1763.42054821;
Epoch: 6; Error: 1618.27710526;
Epoch: 9; Error: 1570.22793468;
Epoch: 12; Error: 1516.26524454;
Epoch: 15; Error: 1490.66190092;
Epoch: 18; Error: 1453.18646337;
Epoch: 21; Error: 1436.7580267;
Epoch: 24; Error: 1427.85096487;
Epoch: 27; Error: 1422.82299482;
Epoch: 30; Error: 1409.28737878;
Epoch: 33; Error: 1405.76075311;
Epoch: 36; Error: 1396.91213602;
Epoch: 39; Error: 1388.9675566;
Epoch: 42; Error: 1381.65002248;
Epoch: 45; Error: 1379.20829593;
Epoch: 48; Error: 1374.53556377;
Epoch: 51; Error: 1371.33856364;
Epoch: 54; Error: 1365.08533852;
Epoch: 57; Error: 1358.34359046;
Epoch: 60; Error: 1354.22253527;
Epoch: 63; Error: 1351.84808745;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1803.26693017;
Epoch: 6; Error: 1648.34668557;
Epoch: 9; Error: 1576.10296677;
Epoch: 12; Error: 1532.94874546;
Epoch: 15; Error: 1503.94398858;
Epoch: 18; Error: 1478.50524945;
Epoch: 21; Error: 1466.71472023;
Epoch: 24; Error: 1457.26677455;
Epoch: 27; Error: 1435.27583523;
Epoch: 30; Error: 1418.96409297;
Epoch: 33; Error: 1400.98540501;
Epoch: 36; Error: 1392.08585979;
Epoch: 39; Error: 1379.55230264;
Epoch: 42; Error: 1370.39586122;
Epoch: 45; Error: 1358.06226035;
Epoch: 48; Error: 1349.11688213;
Epoch: 51; Error: 1342.43854969;
Epoch: 54; Error: 1333.87901464;
Epoch: 57; Error: 1325.71397154;
Epoch: 60; Error: 1317.12465524;
Epoch: 63; Error: 1307.19981858;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1774.95506825;
Epoch: 6; Error: 1647.64464728;
Epoch: 9; Error: 1582.07340645;
Epoch: 12; Error: 1557.74257743;
Epoch: 15; Error: 1532.57512799;
Epoch: 18; Error: 1515.54976866;
Epoch: 21; Error: 1498.05941051;
Epoch: 24; Error: 1482.38382738;
Epoch: 27; Error: 1468.80849554;
Epoch: 30; Error: 1437.69157592;
Epoch: 33; Error: 1424.1184716;
Epoch: 36; Error: 1412.05143142;
Epoch: 39; Error: 1404.21826278;
Epoch: 42; Error: 1398.16966381;
Epoch: 45; Error: 1391.49420851;
Epoch: 48; Error: 1387.09161026;
Epoch: 51; Error: 1380.79061967;
Epoch: 54; Error: 1376.71793493;
Epoch: 57; Error: 1372.61275362;
Epoch: 60; Error: 1370.51705955;
Epoch: 63; Error: 1368.28191574;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1665.14620817;
Epoch: 6; Error: 1559.85005184;
Epoch: 9; Error: 1499.5217627;
Epoch: 12; Error: 1466.07975426;
Epoch: 15; Error: 1435.54022771;
Epoch: 18; Error: 1420.39397389;
Epoch: 21; Error: 1400.69527533;
Epoch: 24; Error: 1384.9709215;
Epoch: 27; Error: 1372.21735613;
Epoch: 30; Error: 1361.57326375;
Epoch: 33; Error: 1353.04652765;
Epoch: 36; Error: 1347.95370734;
Epoch: 39; Error: 1344.87902145;
Epoch: 42; Error: 1341.70393706;
Epoch: 45; Error: 1338.57451176;
Epoch: 48; Error: 1335.53116547;
Epoch: 51; Error: 1332.75714228;
Epoch: 54; Error: 1329.45547144;
Epoch: 57; Error: 1325.60672133;
Epoch: 60; Error: 1323.8515371;
Epoch: 63; Error: 1319.76040056;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1789.66830822;
Epoch: 6; Error: 1702.63419508;
Epoch: 9; Error: 1621.9163683;
Epoch: 12; Error: 1525.26655563;
Epoch: 15; Error: 1481.26000462;
Epoch: 18; Error: 1464.91866079;
Epoch: 21; Error: 1451.82741712;
Epoch: 24; Error: 1432.05926818;
Epoch: 27; Error: 1418.1512596;
Epoch: 30; Error: 1406.5268183;
Epoch: 33; Error: 1394.44298849;
Epoch: 36; Error: 1383.20682783;
Epoch: 39; Error: 1375.42941097;
Epoch: 42; Error: 1369.4970536;
Epoch: 45; Error: 1362.81403853;
Epoch: 48; Error: 1353.69884553;
Epoch: 51; Error: 1348.13492702;
Epoch: 54; Error: 1343.18067426;
Epoch: 57; Error: 1338.80036591;
Epoch: 60; Error: 1334.24261413;
Epoch: 63; Error: 1331.64413846;
The maximum number of train epochs is reached
Best train error: 1306.76942002...
Best Net 0: <neurolab.core.Net object at 0x10e42bbd0>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 2/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 1  2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 30 35 36 37 40 41 42
 43 44 45 51 53]
word_freq_all: [ 0.01563332]
word_freq_3d: [ 0.01141002]
word_freq_remove: [-0.05151143]
word_freq_order: [ 0.16484212]
word_freq_receive: [ 0.06602482]
word_freq_people: [ 0.05278337]
word_freq_report: [ 0.13126483]
word_freq_addresses: [ 0.05784174]
word_freq_you: [-0.04838451]
word_freq_credit: [ 0.02121367]
word_freq_your: [-0.04544397]
word_freq_font: [ 0.10610168]
word_freq_000: [ 0.0629772]
word_freq_money: [ 0.04772592]
word_freq_hpl: [-0.01419347]
word_freq_george: [-0.06755315]
word_freq_650: [-0.0250719]
word_freq_labs: [-0.02614713]
word_freq_857: [ 0.01651181]
word_freq_1999: [ 0.04259048]
word_freq_parts: [-0.01085062]
word_freq_pm: [-0.02381764]
word_freq_meeting: [-0.03546265]
word_freq_original: [-0.01979587]
word_freq_project: [-0.02475755]
word_freq_re: [-0.04865378]
word_freq_edu: [-0.02559164]
word_freq_table: [ 0.01117152]
char_freq_$: [ 0.10963597]
capital_run_length_average: [ 0.12857415]
Cross validation fold 2/10
Train indices: [   0    1    3 ..., 4597 4599 4600]
Test indices: [   2   26   28   46   51   55   74   82  100  137  138  143  146  150  153
  154  159  166  181  183  220  229  232  238  241  243  261  275  277  279
  289  296  301  311  323  338  360  364  367  368  393  416  420  433  435
  436  449  467  478  484  488  496  514  568  573  585  597  605  614  634
  646  649  652  668  670  672  676  692  696  697  748  758  765  768  771
  773  784  795  797  812  814  819  821  849  852  854  857  860  861  863
  876  890  907  924  942  943  990  995 1030 1040 1042 1058 1060 1061 1067
 1073 1074 1081 1082 1084 1093 1099 1120 1123 1141 1154 1158 1162 1169 1202
 1215 1223 1226 1236 1243 1265 1267 1277 1278 1281 1290 1293 1300 1307 1312
 1323 1327 1332 1333 1350 1357 1389 1394 1397 1398 1401 1417 1421 1436 1445
 1447 1461 1463 1476 1483 1488 1500 1503 1511 1527 1545 1553 1555 1575 1581
 1588 1591 1636 1649 1667 1671 1720 1734 1741 1754 1761 1766 1772 1796 1797
 1810 1818 1819 1846 1854 1861 1865 1868 1871 1872 1873 1897 1912 1913 1920
 1930 1933 1954 1980 1989 2059 2085 2089 2093 2098 2108 2114 2124 2135 2141
 2146 2155 2162 2169 2180 2187 2189 2202 2233 2234 2250 2265 2274 2284 2286
 2304 2315 2322 2327 2364 2377 2380 2386 2388 2389 2390 2409 2412 2423 2426
 2449 2453 2505 2506 2509 2512 2549 2558 2563 2564 2566 2578 2586 2601 2604
 2609 2627 2633 2641 2644 2680 2693 2699 2712 2714 2733 2741 2744 2749 2757
 2774 2778 2786 2791 2792 2798 2800 2802 2803 2808 2810 2812 2816 2820 2824
 2857 2860 2890 2906 2913 2924 2946 2974 2981 2984 2985 2987 3007 3037 3043
 3064 3069 3072 3075 3089 3094 3096 3126 3145 3149 3158 3169 3170 3180 3213
 3222 3224 3231 3232 3237 3255 3258 3264 3265 3266 3272 3273 3279 3284 3319
 3336 3337 3352 3357 3360 3363 3370 3371 3379 3389 3395 3400 3422 3429 3436
 3444 3453 3460 3466 3477 3485 3489 3496 3508 3513 3523 3538 3554 3560 3569
 3603 3611 3613 3615 3619 3629 3649 3667 3682 3689 3690 3701 3703 3710 3725
 3727 3732 3748 3757 3761 3766 3770 3776 3788 3822 3828 3836 3842 3850 3878
 3896 3898 3912 3923 3932 3943 3956 3962 3983 3985 4000 4011 4027 4036 4063
 4087 4091 4097 4101 4116 4122 4132 4135 4139 4143 4145 4149 4152 4153 4160
 4193 4212 4222 4224 4239 4248 4264 4276 4280 4288 4304 4308 4312 4316 4327
 4350 4352 4370 4377 4379 4387 4396 4398 4423 4449 4454 4457 4479 4485 4503
 4527 4532 4549 4571 4576 4580 4591 4592 4595 4598]
Features no: 30

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1545.08693642;
Epoch: 6; Error: 1457.10887429;
Epoch: 9; Error: 1416.17962386;
Epoch: 12; Error: 1360.04851708;
Epoch: 15; Error: 1344.00540739;
Epoch: 18; Error: 1325.65693926;
Epoch: 21; Error: 1311.47790311;
Epoch: 24; Error: 1265.29098316;
Epoch: 27; Error: 1245.82986469;
Epoch: 30; Error: 1234.15510032;
Epoch: 33; Error: 1216.76808748;
Epoch: 36; Error: 1204.87693779;
Epoch: 39; Error: 1199.91998536;
Epoch: 42; Error: 1190.13826927;
Epoch: 45; Error: 1182.43524075;
Epoch: 48; Error: 1177.0787408;
Epoch: 51; Error: 1170.49900586;
Epoch: 54; Error: 1163.20418464;
Epoch: 57; Error: 1156.5550653;
Epoch: 60; Error: 1147.69195631;
Epoch: 63; Error: 1140.32149877;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1520.36216624;
Epoch: 6; Error: 1375.06652945;
Epoch: 9; Error: 1334.9564408;
Epoch: 12; Error: 1300.24707867;
Epoch: 15; Error: 1277.52870259;
Epoch: 18; Error: 1257.23443512;
Epoch: 21; Error: 1243.1458302;
Epoch: 24; Error: 1234.64216036;
Epoch: 27; Error: 1228.84462897;
Epoch: 30; Error: 1222.21699417;
Epoch: 33; Error: 1215.51791536;
Epoch: 36; Error: 1208.0277438;
Epoch: 39; Error: 1201.45478933;
Epoch: 42; Error: 1197.48500246;
Epoch: 45; Error: 1193.9414094;
Epoch: 48; Error: 1189.15003038;
Epoch: 51; Error: 1183.28931554;
Epoch: 54; Error: 1180.0629751;
Epoch: 57; Error: 1177.90787361;
Epoch: 60; Error: 1175.70249428;
Epoch: 63; Error: 1171.74720388;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1564.29193395;
Epoch: 6; Error: 1495.60539168;
Epoch: 9; Error: 1450.06852048;
Epoch: 12; Error: 1413.28497811;
Epoch: 15; Error: 1380.29914297;
Epoch: 18; Error: 1354.35829978;
Epoch: 21; Error: 1332.13881312;
Epoch: 24; Error: 1322.63133319;
Epoch: 27; Error: 1315.72576241;
Epoch: 30; Error: 1309.92733224;
Epoch: 33; Error: 1302.56267252;
Epoch: 36; Error: 1295.44784671;
Epoch: 39; Error: 1289.35183928;
Epoch: 42; Error: 1285.41358633;
Epoch: 45; Error: 1282.39767208;
Epoch: 48; Error: 1277.32426202;
Epoch: 51; Error: 1273.11435486;
Epoch: 54; Error: 1269.66767431;
Epoch: 57; Error: 1267.38991356;
Epoch: 60; Error: 1266.0641431;
Epoch: 63; Error: 1263.77473349;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1597.08426713;
Epoch: 6; Error: 1512.27458332;
Epoch: 9; Error: 1439.95092457;
Epoch: 12; Error: 1420.74835394;
Epoch: 15; Error: 1394.02306096;
Epoch: 18; Error: 1375.56570193;
Epoch: 21; Error: 1359.76353105;
Epoch: 24; Error: 1352.01738621;
Epoch: 27; Error: 1324.8612967;
Epoch: 30; Error: 1313.09049182;
Epoch: 33; Error: 1305.87272872;
Epoch: 36; Error: 1296.99644185;
Epoch: 39; Error: 1284.83146792;
Epoch: 42; Error: 1272.10374902;
Epoch: 45; Error: 1264.58771698;
Epoch: 48; Error: 1255.82654109;
Epoch: 51; Error: 1250.00518295;
Epoch: 54; Error: 1242.0857255;
Epoch: 57; Error: 1232.69372898;
Epoch: 60; Error: 1227.4791775;
Epoch: 63; Error: 1222.66715606;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1690.43434148;
Epoch: 6; Error: 1579.18113778;
Epoch: 9; Error: 1507.81112177;
Epoch: 12; Error: 1476.77466519;
Epoch: 15; Error: 1443.20788072;
Epoch: 18; Error: 1402.33673478;
Epoch: 21; Error: 1359.0823336;
Epoch: 24; Error: 1342.12571948;
Epoch: 27; Error: 1333.33162734;
Epoch: 30; Error: 1320.78899693;
Epoch: 33; Error: 1309.82025831;
Epoch: 36; Error: 1297.10451059;
Epoch: 39; Error: 1287.10582214;
Epoch: 42; Error: 1277.37019407;
Epoch: 45; Error: 1268.16217463;
Epoch: 48; Error: 1258.11481166;
Epoch: 51; Error: 1250.52787771;
Epoch: 54; Error: 1245.18886806;
Epoch: 57; Error: 1239.67777673;
Epoch: 60; Error: 1233.68805231;
Epoch: 63; Error: 1232.4682609;
The maximum number of train epochs is reached
Best train error: 1138.31813994...
Best Net 1: <neurolab.core.Net object at 0x10e51ded0>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 3/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 30 31 35 37 40 41 42 43
 44 51 53]
word_freq_3d: [ 0.01348666]
word_freq_remove: [-0.05322111]
word_freq_order: [ 0.17070915]
word_freq_receive: [ 0.07385267]
word_freq_people: [ 0.05285789]
word_freq_report: [ 0.13481545]
word_freq_addresses: [ 0.0681289]
word_freq_you: [-0.04740163]
word_freq_credit: [ 0.02094402]
word_freq_your: [-0.04297805]
word_freq_font: [ 0.10300912]
word_freq_000: [ 0.05810336]
word_freq_money: [ 0.0423643]
word_freq_hpl: [-0.01356222]
word_freq_george: [-0.06799149]
word_freq_650: [-0.02660088]
word_freq_labs: [-0.02680571]
word_freq_857: [ 0.01540159]
word_freq_data: [ 0.02783701]
word_freq_1999: [ 0.03598921]
word_freq_pm: [-0.0249219]
word_freq_meeting: [-0.03858063]
word_freq_original: [-0.02078222]
word_freq_project: [-0.0363882]
word_freq_re: [-0.05139583]
word_freq_edu: [-0.02511792]
char_freq_$: [ 0.10734664]
capital_run_length_average: [ 0.12376579]
Cross validation fold 3/10
Train indices: [   1    2    3 ..., 4596 4598 4599]
Test indices: [   0   16   23   34   42   43   48   66   72   85  117  125  164  168  169
  178  180  186  187  194  202  222  233  242  244  250  259  262  269  272
  283  298  299  300  305  314  320  321  348  349  352  353  357  379  389
  392  401  404  412  417  418  425  430  437  438  470  476  493  494  529
  536  539  555  558  570  572  576  578  588  596  612  620  632  645  654
  684  689  713  717  728  751  761  781  825  838  841  855  864  868  872
  902  903  908  909  913  914  925  935  950  953  963  971  977  997 1001
 1002 1011 1024 1039 1043 1066 1078 1090 1118 1132 1152 1156 1159 1191 1197
 1201 1214 1221 1238 1250 1258 1266 1274 1310 1311 1386 1399 1400 1405 1412
 1413 1419 1422 1427 1480 1481 1486 1504 1507 1514 1531 1534 1551 1563 1579
 1595 1605 1609 1640 1652 1654 1655 1658 1664 1669 1672 1675 1680 1709 1749
 1750 1755 1756 1764 1770 1771 1773 1776 1778 1795 1801 1843 1849 1852 1863
 1879 1919 1941 1951 1952 1956 1958 1960 1964 1968 1986 1988 2005 2006 2035
 2036 2042 2066 2072 2080 2094 2095 2118 2123 2125 2144 2152 2161 2176 2178
 2185 2191 2198 2200 2208 2218 2222 2225 2228 2230 2232 2239 2244 2255 2257
 2260 2282 2290 2291 2317 2323 2335 2338 2343 2350 2352 2361 2381 2383 2400
 2404 2432 2434 2436 2442 2448 2451 2455 2462 2466 2467 2485 2489 2499 2501
 2508 2520 2535 2537 2551 2559 2570 2574 2589 2592 2593 2596 2600 2614 2617
 2622 2638 2648 2649 2651 2658 2669 2671 2676 2701 2705 2725 2727 2732 2746
 2748 2760 2763 2776 2779 2789 2795 2801 2804 2811 2813 2826 2835 2853 2867
 2872 2887 2895 2915 2928 2941 2944 2960 2968 2986 2997 3021 3028 3032 3033
 3041 3048 3082 3093 3098 3107 3114 3129 3150 3179 3194 3201 3214 3221 3241
 3245 3252 3280 3295 3302 3307 3353 3378 3399 3404 3409 3431 3439 3455 3461
 3467 3486 3504 3522 3541 3543 3549 3550 3573 3595 3604 3621 3622 3626 3627
 3632 3635 3636 3640 3641 3646 3675 3693 3711 3718 3726 3743 3752 3759 3773
 3774 3794 3800 3810 3817 3820 3831 3838 3840 3844 3895 3899 3905 3907 3911
 3917 3934 3939 3941 3972 3992 3994 3996 3997 3998 4022 4031 4068 4104 4106
 4108 4118 4134 4140 4159 4166 4170 4173 4174 4178 4191 4194 4230 4249 4254
 4262 4300 4301 4302 4329 4340 4342 4347 4365 4367 4378 4386 4392 4394 4400
 4419 4424 4425 4438 4442 4443 4450 4460 4469 4475 4476 4484 4520 4521 4524
 4526 4542 4545 4553 4558 4565 4584 4587 4597 4600]
Features no: 28

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1890.85938035;
Epoch: 6; Error: 1774.31413917;
Epoch: 9; Error: 1722.36185352;
Epoch: 12; Error: 1695.0949507;
Epoch: 15; Error: 1681.30736932;
Epoch: 18; Error: 1670.53626154;
Epoch: 21; Error: 1654.34597189;
Epoch: 24; Error: 1642.43213919;
Epoch: 27; Error: 1636.10384139;
Epoch: 30; Error: 1627.61470926;
Epoch: 33; Error: 1621.47687041;
Epoch: 36; Error: 1616.16323141;
Epoch: 39; Error: 1608.08404275;
Epoch: 42; Error: 1600.42413253;
Epoch: 45; Error: 1592.1846474;
Epoch: 48; Error: 1589.09977512;
Epoch: 51; Error: 1585.95659295;
Epoch: 54; Error: 1581.03333822;
Epoch: 57; Error: 1575.95491074;
Epoch: 60; Error: 1572.05014329;
Epoch: 63; Error: 1567.30126664;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 2054.85706053;
Epoch: 6; Error: 1906.8583217;
Epoch: 9; Error: 1797.3655441;
Epoch: 12; Error: 1740.4171282;
Epoch: 15; Error: 1694.251605;
Epoch: 18; Error: 1668.24432335;
Epoch: 21; Error: 1653.28475075;
Epoch: 24; Error: 1643.17938888;
Epoch: 27; Error: 1640.55666101;
Epoch: 30; Error: 1632.4096083;
Epoch: 33; Error: 1625.33262752;
Epoch: 36; Error: 1618.58116472;
Epoch: 39; Error: 1614.95092146;
Epoch: 42; Error: 1611.06549131;
Epoch: 45; Error: 1609.40149955;
Epoch: 48; Error: 1607.40317989;
Epoch: 51; Error: 1602.91228256;
Epoch: 54; Error: 1599.22326163;
Epoch: 57; Error: 1593.03052127;
Epoch: 60; Error: 1588.29011264;
Epoch: 63; Error: 1581.97942404;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 2122.0827009;
Epoch: 6; Error: 2003.86985779;
Epoch: 9; Error: 1869.27334448;
Epoch: 12; Error: 1813.67371752;
Epoch: 15; Error: 1785.72347819;
Epoch: 18; Error: 1771.46975021;
Epoch: 21; Error: 1759.19399464;
Epoch: 24; Error: 1749.90483171;
Epoch: 27; Error: 1744.51595781;
Epoch: 30; Error: 1739.93056567;
Epoch: 33; Error: 1736.49705239;
Epoch: 36; Error: 1724.60226094;
Epoch: 39; Error: 1720.75829232;
Epoch: 42; Error: 1712.65221827;
Epoch: 45; Error: 1704.02991611;
Epoch: 48; Error: 1695.81362943;
Epoch: 51; Error: 1685.94973224;
Epoch: 54; Error: 1676.56054642;
Epoch: 57; Error: 1666.42031983;
Epoch: 60; Error: 1663.01677816;
Epoch: 63; Error: 1649.57881399;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1998.38130148;
Epoch: 6; Error: 1900.65026937;
Epoch: 9; Error: 1849.80173074;
Epoch: 12; Error: 1829.15880858;
Epoch: 15; Error: 1790.88237677;
Epoch: 18; Error: 1762.80170553;
Epoch: 21; Error: 1739.14511141;
Epoch: 24; Error: 1716.53955488;
Epoch: 27; Error: 1709.32727324;
Epoch: 30; Error: 1695.76784938;
Epoch: 33; Error: 1684.4776611;
Epoch: 36; Error: 1670.78670164;
Epoch: 39; Error: 1659.80153886;
Epoch: 42; Error: 1646.29215282;
Epoch: 45; Error: 1642.66777419;
Epoch: 48; Error: 1633.03049675;
Epoch: 51; Error: 1626.0985456;
Epoch: 54; Error: 1617.93662199;
Epoch: 57; Error: 1615.37814205;
Epoch: 60; Error: 1611.69167784;
Epoch: 63; Error: 1606.62277478;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 2025.12380687;
Epoch: 6; Error: 1969.98810771;
Epoch: 9; Error: 1867.99763506;
Epoch: 12; Error: 1812.37910988;
Epoch: 15; Error: 1791.34144225;
Epoch: 18; Error: 1769.20830239;
Epoch: 21; Error: 1740.53464942;
Epoch: 24; Error: 1695.6791329;
Epoch: 27; Error: 1674.97596871;
Epoch: 30; Error: 1655.02532375;
Epoch: 33; Error: 1632.74148652;
Epoch: 36; Error: 1618.65506191;
Epoch: 39; Error: 1605.51511509;
Epoch: 42; Error: 1594.97407912;
Epoch: 45; Error: 1588.89213976;
Epoch: 48; Error: 1580.22259821;
Epoch: 51; Error: 1574.93565679;
Epoch: 54; Error: 1571.54961421;
Epoch: 57; Error: 1566.11497046;
Epoch: 60; Error: 1562.90653806;
Epoch: 63; Error: 1559.88705278;
The maximum number of train epochs is reached
Best train error: 1558.50980928...
Best Net 2: <neurolab.core.Net object at 0x10e4d2d10>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 4/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 32 35 37 40 41 42 43 44
 51 53]
word_freq_3d: [ 0.01316455]
word_freq_remove: [-0.05307235]
word_freq_order: [ 0.181854]
word_freq_receive: [ 0.0629102]
word_freq_people: [ 0.05097821]
word_freq_report: [ 0.13526795]
word_freq_addresses: [ 0.05522218]
word_freq_you: [-0.04536382]
word_freq_credit: [ 0.02122779]
word_freq_your: [-0.04261633]
word_freq_font: [ 0.09879213]
word_freq_000: [ 0.05803839]
word_freq_money: [ 0.03447633]
word_freq_hpl: [-0.01454461]
word_freq_george: [-0.06691409]
word_freq_650: [-0.02563673]
word_freq_labs: [-0.028609]
word_freq_415: [ 0.01868388]
word_freq_1999: [ 0.0351929]
word_freq_pm: [-0.02346961]
word_freq_meeting: [-0.03553042]
word_freq_original: [-0.01751221]
word_freq_project: [-0.02507584]
word_freq_re: [-0.05392044]
word_freq_edu: [-0.02326187]
char_freq_$: [ 0.12057253]
capital_run_length_average: [ 0.1455147]
Cross validation fold 4/10
Train indices: [   0    1    2 ..., 4598 4599 4600]
Test indices: [  10   17   41   44   49   54   68   76   80   84   87   89  107  112  113
  115  119  139  148  156  165  175  185  191  197  198  240  247  249  286
  309  324  327  345  363  374  377  391  402  427  448  456  473  480  487
  489  490  503  510  528  533  544  553  556  563  564  575  577  592  611
  618  626  633  635  648  651  657  659  662  665  666  680  702  709  715
  720  722  725  727  732  745  752  755  763  804  808  820  831  832  839
  892  897  911  917  919  921  944  947  954  957  960  970  985  987 1008
 1028 1032 1072 1075 1083 1091 1104 1109 1110 1129 1146 1155 1163 1179 1189
 1190 1204 1207 1208 1210 1237 1246 1249 1256 1272 1275 1276 1279 1283 1318
 1319 1325 1336 1355 1367 1373 1374 1383 1392 1425 1433 1444 1458 1477 1479
 1485 1499 1501 1505 1506 1508 1516 1520 1524 1529 1541 1557 1559 1568 1576
 1589 1604 1626 1635 1638 1639 1642 1643 1645 1665 1666 1678 1681 1683 1690
 1694 1705 1708 1716 1717 1738 1763 1779 1791 1799 1806 1809 1812 1822 1826
 1833 1850 1869 1874 1886 1901 1904 1907 1908 1910 1914 1931 1950 1953 1957
 1962 1975 1976 1994 2007 2010 2026 2029 2030 2053 2060 2077 2079 2100 2116
 2126 2130 2131 2160 2173 2194 2199 2206 2215 2221 2236 2247 2252 2258 2259
 2275 2276 2280 2288 2294 2295 2300 2301 2305 2306 2325 2370 2382 2397 2403
 2431 2439 2443 2452 2461 2468 2480 2524 2525 2531 2544 2545 2587 2594 2626
 2647 2655 2657 2662 2674 2678 2688 2698 2718 2731 2737 2751 2752 2758 2764
 2768 2771 2782 2784 2785 2809 2814 2823 2830 2840 2846 2847 2849 2852 2854
 2869 2870 2873 2874 2885 2901 2917 2926 2927 2978 2989 3009 3011 3020 3063
 3074 3091 3092 3105 3106 3108 3113 3117 3128 3134 3143 3147 3153 3159 3162
 3178 3190 3216 3219 3247 3261 3262 3281 3286 3288 3300 3306 3312 3318 3327
 3341 3384 3391 3410 3438 3458 3464 3468 3469 3470 3472 3475 3482 3487 3498
 3499 3514 3517 3520 3564 3597 3598 3599 3612 3620 3633 3654 3655 3661 3671
 3705 3709 3716 3731 3733 3742 3785 3789 3807 3847 3848 3855 3857 3863 3867
 3871 3888 3892 3897 3908 3921 3944 3948 3953 3963 3980 3999 4004 4010 4015
 4016 4024 4026 4030 4034 4037 4041 4062 4073 4074 4076 4121 4128 4129 4157
 4176 4184 4188 4200 4202 4203 4205 4213 4217 4220 4234 4236 4241 4244 4245
 4282 4283 4297 4315 4326 4361 4411 4420 4429 4441 4466 4474 4487 4488 4492
 4496 4498 4528 4536 4540 4563 4566 4573 4577 4589]
Features no: 27

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1920.63669005;
Epoch: 6; Error: 1795.72130925;
Epoch: 9; Error: 1761.01976223;
Epoch: 12; Error: 1730.70778927;
Epoch: 15; Error: 1693.37660571;
Epoch: 18; Error: 1665.4257085;
Epoch: 21; Error: 1653.26382015;
Epoch: 24; Error: 1641.88577699;
Epoch: 27; Error: 1631.10878631;
Epoch: 30; Error: 1622.30709117;
Epoch: 33; Error: 1615.71798938;
Epoch: 36; Error: 1608.26393832;
Epoch: 39; Error: 1602.9082736;
Epoch: 42; Error: 1598.76631437;
Epoch: 45; Error: 1594.61605022;
Epoch: 48; Error: 1590.49604968;
Epoch: 51; Error: 1584.44080424;
Epoch: 54; Error: 1579.38157379;
Epoch: 57; Error: 1570.07193375;
Epoch: 60; Error: 1565.42742005;
Epoch: 63; Error: 1563.20665246;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1887.14484502;
Epoch: 6; Error: 1790.35841256;
Epoch: 9; Error: 1738.96741776;
Epoch: 12; Error: 1732.51778918;
Epoch: 15; Error: 1703.3609753;
Epoch: 18; Error: 1660.17852614;
Epoch: 21; Error: 1639.98973259;
Epoch: 24; Error: 1626.95958027;
Epoch: 27; Error: 1618.48618146;
Epoch: 30; Error: 1610.30359923;
Epoch: 33; Error: 1605.12455325;
Epoch: 36; Error: 1596.50498993;
Epoch: 39; Error: 1587.41349406;
Epoch: 42; Error: 1579.03531486;
Epoch: 45; Error: 1576.27151061;
Epoch: 48; Error: 1568.24621343;
Epoch: 51; Error: 1563.45657197;
Epoch: 54; Error: 1556.5859694;
Epoch: 57; Error: 1552.5118546;
Epoch: 60; Error: 1549.61445299;
Epoch: 63; Error: 1544.81647078;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1911.08653363;
Epoch: 6; Error: 1764.02661911;
Epoch: 9; Error: 1720.43688451;
Epoch: 12; Error: 1690.56239192;
Epoch: 15; Error: 1636.42170425;
Epoch: 18; Error: 1607.83404386;
Epoch: 21; Error: 1594.43026813;
Epoch: 24; Error: 1588.00812259;
Epoch: 27; Error: 1582.97806962;
Epoch: 30; Error: 1577.7637044;
Epoch: 33; Error: 1573.34818534;
Epoch: 36; Error: 1568.99835717;
Epoch: 39; Error: 1565.07970658;
Epoch: 42; Error: 1562.28079686;
Epoch: 45; Error: 1558.63096065;
Epoch: 48; Error: 1554.08177483;
Epoch: 51; Error: 1549.8679045;
Epoch: 54; Error: 1547.25071274;
Epoch: 57; Error: 1544.34444321;
Epoch: 60; Error: 1541.09188947;
Epoch: 63; Error: 1537.86122408;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1842.20009668;
Epoch: 6; Error: 1770.13316713;
Epoch: 9; Error: 1704.6757962;
Epoch: 12; Error: 1658.84645021;
Epoch: 15; Error: 1633.01324112;
Epoch: 18; Error: 1620.2103672;
Epoch: 21; Error: 1606.4545896;
Epoch: 24; Error: 1600.16163737;
Epoch: 27; Error: 1595.58964422;
Epoch: 30; Error: 1591.74607131;
Epoch: 33; Error: 1586.18697775;
Epoch: 36; Error: 1580.27041178;
Epoch: 39; Error: 1574.33676632;
Epoch: 42; Error: 1568.35629452;
Epoch: 45; Error: 1564.14267289;
Epoch: 48; Error: 1561.42296914;
Epoch: 51; Error: 1557.87477299;
Epoch: 54; Error: 1553.72636126;
Epoch: 57; Error: 1551.51469256;
Epoch: 60; Error: 1549.37859414;
Epoch: 63; Error: 1547.17165726;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1963.32395208;
Epoch: 6; Error: 1831.70669144;
Epoch: 9; Error: 1756.07414219;
Epoch: 12; Error: 1727.8775411;
Epoch: 15; Error: 1692.09071575;
Epoch: 18; Error: 1648.57671209;
Epoch: 21; Error: 1633.57348009;
Epoch: 24; Error: 1609.23854007;
Epoch: 27; Error: 1600.36516909;
Epoch: 30; Error: 1578.40696166;
Epoch: 33; Error: 1567.66810381;
Epoch: 36; Error: 1556.44048478;
Epoch: 39; Error: 1550.65604429;
Epoch: 42; Error: 1546.59382485;
Epoch: 45; Error: 1540.75907213;
Epoch: 48; Error: 1531.43735859;
Epoch: 51; Error: 1527.77990181;
Epoch: 54; Error: 1523.90277606;
Epoch: 57; Error: 1520.06037777;
Epoch: 60; Error: 1514.71024676;
Epoch: 63; Error: 1509.89824565;
The maximum number of train epochs is reached
Best train error: 1509.14510783...
Best Net 3: <neurolab.core.Net object at 0x10c673910>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 5/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 30 35 37 40 41 42 43 44
 51 53]
word_freq_3d: [ 0.01669522]
word_freq_remove: [-0.05245164]
word_freq_order: [ 0.15787764]
word_freq_receive: [ 0.06966297]
word_freq_people: [ 0.0585864]
word_freq_report: [ 0.13941591]
word_freq_addresses: [ 0.06658131]
word_freq_you: [-0.04645987]
word_freq_credit: [ 0.01816251]
word_freq_your: [-0.04712769]
word_freq_font: [ 0.10575333]
word_freq_000: [ 0.06140166]
word_freq_money: [ 0.0368346]
word_freq_hpl: [-0.01474476]
word_freq_george: [-0.06724333]
word_freq_650: [-0.02752667]
word_freq_labs: [-0.02458526]
word_freq_857: [ 0.01596775]
word_freq_1999: [ 0.03730206]
word_freq_pm: [-0.02379579]
word_freq_meeting: [-0.03744809]
word_freq_original: [-0.01594833]
word_freq_project: [-0.02551638]
word_freq_re: [-0.05020777]
word_freq_edu: [-0.02749162]
char_freq_$: [ 0.12706891]
capital_run_length_average: [ 0.13691266]
Cross validation fold 5/10
Train indices: [   0    1    2 ..., 4598 4599 4600]
Test indices: [   9   31   33   39   71   73   95  110  111  123  140  157  161  189  195
  205  208  246  253  258  263  268  276  281  295  307  312  315  330  333
  340  343  359  366  372  376  384  387  400  411  424  461  475  479  508
  516  517  523  525  531  535  542  551  559  565  571  579  586  587  599
  602  631  653  658  667  673  704  707  726  734  743  774  778  782  791
  801  807  829  844  889  894  910  918  920  926  927  932  949  955  975
  983 1006 1014 1022 1026 1047 1048 1063 1064 1071 1080 1087 1095 1097 1112
 1113 1115 1116 1119 1124 1125 1127 1135 1147 1165 1173 1176 1192 1206 1212
 1216 1227 1232 1233 1239 1252 1285 1301 1306 1309 1321 1329 1339 1359 1364
 1368 1387 1390 1391 1402 1432 1457 1467 1487 1493 1495 1510 1532 1537 1547
 1549 1573 1590 1592 1598 1603 1611 1612 1631 1661 1677 1679 1689 1698 1700
 1710 1714 1725 1747 1758 1800 1803 1807 1817 1830 1836 1837 1851 1853 1866
 1890 1896 1898 1903 1906 1921 1925 1936 1944 1963 1969 1982 2001 2018 2028
 2037 2043 2056 2061 2062 2070 2078 2082 2086 2088 2097 2102 2109 2117 2132
 2134 2136 2151 2156 2163 2167 2171 2174 2181 2195 2201 2207 2243 2245 2249
 2253 2277 2279 2293 2312 2339 2345 2355 2363 2384 2401 2413 2415 2428 2445
 2447 2476 2478 2494 2498 2502 2542 2546 2550 2568 2569 2576 2577 2581 2584
 2585 2588 2618 2624 2628 2639 2643 2650 2659 2663 2666 2677 2685 2692 2697
 2704 2707 2716 2770 2775 2807 2834 2837 2838 2861 2864 2877 2883 2903 2918
 2922 2938 2953 2958 2965 2970 2972 2980 3000 3002 3010 3019 3025 3038 3040
 3047 3057 3073 3079 3101 3120 3135 3138 3146 3151 3154 3176 3227 3233 3254
 3271 3285 3290 3294 3313 3317 3331 3340 3349 3351 3362 3369 3383 3411 3414
 3415 3421 3423 3481 3492 3510 3528 3552 3555 3556 3563 3571 3590 3593 3594
 3606 3644 3653 3658 3678 3681 3683 3694 3695 3699 3707 3717 3724 3755 3780
 3792 3795 3801 3813 3815 3826 3829 3853 3859 3865 3873 3875 3883 3886 3889
 3900 3903 3918 3937 3938 3946 3951 3954 3955 3973 3975 3990 4012 4014 4019
 4020 4023 4025 4028 4038 4051 4058 4066 4079 4084 4094 4131 4151 4163 4169
 4177 4180 4182 4185 4189 4195 4209 4210 4211 4221 4228 4240 4243 4251 4273
 4279 4306 4307 4322 4324 4333 4337 4339 4345 4348 4360 4381 4382 4414 4416
 4418 4459 4465 4468 4470 4482 4486 4506 4508 4509 4515 4516 4523 4529 4534
 4538 4541 4544 4550 4551 4564 4569 4581 4585 4593]
Features no: 27

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1946.15871239;
Epoch: 6; Error: 1830.60704213;
Epoch: 9; Error: 1795.96332177;
Epoch: 12; Error: 1756.02856774;
Epoch: 15; Error: 1725.45585578;
Epoch: 18; Error: 1704.33102454;
Epoch: 21; Error: 1694.42883386;
Epoch: 24; Error: 1670.81048509;
Epoch: 27; Error: 1647.97488227;
Epoch: 30; Error: 1630.35390616;
Epoch: 33; Error: 1617.26108366;
Epoch: 36; Error: 1595.33038934;
Epoch: 39; Error: 1569.40081745;
Epoch: 42; Error: 1563.78583288;
Epoch: 45; Error: 1552.70929169;
Epoch: 48; Error: 1547.44891587;
Epoch: 51; Error: 1539.92277206;
Epoch: 54; Error: 1537.22218058;
Epoch: 57; Error: 1531.90930432;
Epoch: 60; Error: 1523.27837157;
Epoch: 63; Error: 1515.95342814;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1871.12908126;
Epoch: 6; Error: 1746.95943641;
Epoch: 9; Error: 1712.73345936;
Epoch: 12; Error: 1674.18446176;
Epoch: 15; Error: 1640.21762814;
Epoch: 18; Error: 1604.15486618;
Epoch: 21; Error: 1584.97869349;
Epoch: 24; Error: 1568.05034088;
Epoch: 27; Error: 1557.83685592;
Epoch: 30; Error: 1552.16757489;
Epoch: 33; Error: 1548.70395624;
Epoch: 36; Error: 1538.86917838;
Epoch: 39; Error: 1533.17944482;
Epoch: 42; Error: 1527.04086174;
Epoch: 45; Error: 1522.96516876;
Epoch: 48; Error: 1519.72665423;
Epoch: 51; Error: 1515.23740632;
Epoch: 54; Error: 1511.97373733;
Epoch: 57; Error: 1507.50303487;
Epoch: 60; Error: 1502.2953025;
Epoch: 63; Error: 1498.27809688;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1918.26416417;
Epoch: 6; Error: 1766.1392763;
Epoch: 9; Error: 1719.55196582;
Epoch: 12; Error: 1714.63860579;
Epoch: 15; Error: 1702.12841207;
Epoch: 18; Error: 1680.51742246;
Epoch: 21; Error: 1667.22798518;
Epoch: 24; Error: 1648.78324032;
Epoch: 27; Error: 1638.23833023;
Epoch: 30; Error: 1627.52893041;
Epoch: 33; Error: 1610.01725111;
Epoch: 36; Error: 1598.90659715;
Epoch: 39; Error: 1588.24830994;
Epoch: 42; Error: 1581.31539932;
Epoch: 45; Error: 1575.39765182;
Epoch: 48; Error: 1572.07440088;
Epoch: 51; Error: 1565.88716713;
Epoch: 54; Error: 1558.27015285;
Epoch: 57; Error: 1552.56271129;
Epoch: 60; Error: 1546.03548865;
Epoch: 63; Error: 1535.06366971;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1931.01707574;
Epoch: 6; Error: 1748.72328874;
Epoch: 9; Error: 1705.45085976;
Epoch: 12; Error: 1680.5343377;
Epoch: 15; Error: 1643.06885551;
Epoch: 18; Error: 1628.13284838;
Epoch: 21; Error: 1619.78496023;
Epoch: 24; Error: 1606.2689541;
Epoch: 27; Error: 1582.90922795;
Epoch: 30; Error: 1574.28770027;
Epoch: 33; Error: 1564.56332135;
Epoch: 36; Error: 1557.25792709;
Epoch: 39; Error: 1550.21892657;
Epoch: 42; Error: 1543.31568501;
Epoch: 45; Error: 1535.5174311;
Epoch: 48; Error: 1530.27825102;
Epoch: 51; Error: 1523.95304565;
Epoch: 54; Error: 1520.36130765;
Epoch: 57; Error: 1513.92092371;
Epoch: 60; Error: 1507.71761731;
Epoch: 63; Error: 1505.95245798;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1811.12233404;
Epoch: 6; Error: 1741.4204788;
Epoch: 9; Error: 1675.52099481;
Epoch: 12; Error: 1619.07105953;
Epoch: 15; Error: 1576.03278089;
Epoch: 18; Error: 1562.83036273;
Epoch: 21; Error: 1545.75375003;
Epoch: 24; Error: 1532.54177033;
Epoch: 27; Error: 1521.98720509;
Epoch: 30; Error: 1510.25969526;
Epoch: 33; Error: 1504.37855458;
Epoch: 36; Error: 1497.36969276;
Epoch: 39; Error: 1486.86768932;
Epoch: 42; Error: 1476.84659264;
Epoch: 45; Error: 1469.15260107;
Epoch: 48; Error: 1459.78656655;
Epoch: 51; Error: 1452.93896447;
Epoch: 54; Error: 1442.29265626;
Epoch: 57; Error: 1438.3699037;
Epoch: 60; Error: 1431.90500341;
Epoch: 63; Error: 1429.15282601;
The maximum number of train epochs is reached
Best train error: 1427.92081756...
Best Net 4: <neurolab.core.Net object at 0x10c6a6550>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 6/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  4  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 27 28 29 30 35 37 40 41
 42 43 44 51 53]
word_freq_3d: [ 0.01734146]
word_freq_over: [ 0.01941544]
word_freq_remove: [-0.05162852]
word_freq_order: [ 0.15880364]
word_freq_receive: [ 0.06859245]
word_freq_people: [ 0.04934441]
word_freq_report: [ 0.15193066]
word_freq_addresses: [ 0.06577677]
word_freq_you: [-0.05075102]
word_freq_credit: [ 0.01719819]
word_freq_your: [-0.04556281]
word_freq_font: [ 0.09865229]
word_freq_000: [ 0.06792349]
word_freq_money: [ 0.04003166]
word_freq_hpl: [-0.01472224]
word_freq_george: [-0.06818995]
word_freq_650: [-0.02661146]
word_freq_lab: [-0.01473457]
word_freq_labs: [-0.02995268]
word_freq_telnet: [ 0.01670376]
word_freq_857: [ 0.01413319]
word_freq_1999: [ 0.03825701]
word_freq_pm: [-0.02426315]
word_freq_meeting: [-0.03241156]
word_freq_original: [-0.01848454]
word_freq_project: [-0.02604863]
word_freq_re: [-0.05417727]
word_freq_edu: [-0.02552852]
char_freq_$: [ 0.09841383]
capital_run_length_average: [ 0.12520828]
Cross validation fold 6/10
Train indices: [   0    1    2 ..., 4598 4599 4600]
Test indices: [   5    8   15   35   52   58   60   63   81   98   99  121  127  147  171
  172  184  204  210  248  288  292  294  302  308  317  342  346  350  355
  356  370  380  388  397  399  419  426  458  463  469  472  492  520  526
  530  532  540  543  560  567  569  582  591  615  619  623  638  655  677
  730  739  741  750  757  800  806  816  822  830  836  840  848  862  873
  877  879  883  905  922  929  931  933  966  989  998 1016 1031 1033 1046
 1055 1107 1122 1148 1166 1168 1184 1194 1198 1200 1205 1209 1220 1230 1247
 1248 1251 1253 1270 1271 1280 1282 1315 1316 1331 1337 1341 1360 1380 1404
 1414 1424 1426 1442 1449 1455 1494 1521 1530 1543 1562 1565 1569 1571 1597
 1599 1610 1615 1633 1650 1656 1659 1676 1691 1713 1730 1744 1752 1775 1777
 1784 1802 1805 1808 1828 1832 1856 1857 1880 1882 1883 1929 1991 1992 1995
 1997 2002 2004 2012 2013 2017 2027 2034 2038 2041 2045 2048 2055 2063 2064
 2067 2071 2075 2081 2083 2091 2103 2111 2115 2143 2158 2183 2186 2227 2231
 2285 2299 2311 2326 2329 2331 2368 2369 2387 2393 2395 2396 2399 2405 2406
 2416 2429 2430 2438 2459 2469 2471 2472 2475 2479 2503 2504 2515 2517 2518
 2519 2521 2534 2539 2554 2555 2579 2580 2583 2590 2605 2613 2615 2619 2625
 2630 2636 2637 2653 2694 2695 2702 2709 2711 2719 2722 2723 2724 2736 2780
 2781 2794 2799 2815 2817 2828 2856 2865 2876 2893 2897 2900 2909 2916 2925
 2930 2939 2950 2951 2959 2962 2990 3004 3055 3065 3068 3076 3078 3103 3104
 3112 3148 3168 3196 3205 3206 3207 3210 3215 3223 3240 3244 3246 3257 3259
 3267 3287 3293 3299 3301 3311 3328 3343 3346 3361 3367 3368 3376 3390 3394
 3396 3406 3418 3420 3428 3430 3433 3443 3445 3447 3452 3456 3476 3491 3495
 3500 3503 3505 3506 3507 3518 3529 3531 3533 3534 3536 3540 3542 3561 3565
 3582 3583 3584 3585 3591 3601 3630 3631 3645 3650 3651 3664 3674 3687 3688
 3697 3708 3713 3715 3719 3729 3737 3740 3760 3793 3796 3803 3805 3808 3812
 3814 3816 3827 3835 3843 3845 3854 3856 3864 3882 3885 3887 3914 3916 3920
 3926 3940 3942 3945 3959 3969 3977 3979 3988 4017 4053 4064 4065 4070 4080
 4093 4096 4107 4114 4117 4124 4133 4148 4154 4168 4171 4235 4242 4250 4253
 4281 4284 4314 4336 4341 4344 4346 4358 4359 4368 4369 4371 4374 4375 4380
 4390 4395 4401 4408 4435 4448 4452 4456 4464 4471 4489 4500 4501 4505 4507
 4513 4519 4522 4525 4555 4557 4559 4568 4586 4588]
Features no: 30

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 2044.06206043;
Epoch: 6; Error: 1915.93839135;
Epoch: 9; Error: 1804.98487572;
Epoch: 12; Error: 1760.87905251;
Epoch: 15; Error: 1734.36847416;
Epoch: 18; Error: 1706.92110375;
Epoch: 21; Error: 1687.17762225;
Epoch: 24; Error: 1665.65812603;
Epoch: 27; Error: 1648.84364778;
Epoch: 30; Error: 1634.44563797;
Epoch: 33; Error: 1616.53515283;
Epoch: 36; Error: 1598.11011383;
Epoch: 39; Error: 1585.4162173;
Epoch: 42; Error: 1564.52595377;
Epoch: 45; Error: 1552.60460777;
Epoch: 48; Error: 1534.74677414;
Epoch: 51; Error: 1511.98577688;
Epoch: 54; Error: 1498.03107833;
Epoch: 57; Error: 1486.77126124;
Epoch: 60; Error: 1479.16680924;
Epoch: 63; Error: 1473.91444826;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1852.24620037;
Epoch: 6; Error: 1762.35309943;
Epoch: 9; Error: 1736.61431405;
Epoch: 12; Error: 1681.6220466;
Epoch: 15; Error: 1657.82166183;
Epoch: 18; Error: 1640.86614885;
Epoch: 21; Error: 1623.07582175;
Epoch: 24; Error: 1608.03024797;
Epoch: 27; Error: 1601.98751183;
Epoch: 30; Error: 1595.03567385;
Epoch: 33; Error: 1589.26187673;
Epoch: 36; Error: 1583.63339834;
Epoch: 39; Error: 1577.25246671;
Epoch: 42; Error: 1572.86179932;
Epoch: 45; Error: 1570.20822206;
Epoch: 48; Error: 1565.45901538;
Epoch: 51; Error: 1560.70351333;
Epoch: 54; Error: 1555.42703033;
Epoch: 57; Error: 1551.72896646;
Epoch: 60; Error: 1547.65570546;
Epoch: 63; Error: 1542.07252035;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1872.63130215;
Epoch: 6; Error: 1778.53905249;
Epoch: 9; Error: 1731.93858445;
Epoch: 12; Error: 1691.26608626;
Epoch: 15; Error: 1673.41489025;
Epoch: 18; Error: 1658.16236055;
Epoch: 21; Error: 1644.06792738;
Epoch: 24; Error: 1623.64073466;
Epoch: 27; Error: 1603.44504069;
Epoch: 30; Error: 1586.39974171;
Epoch: 33; Error: 1578.15606635;
Epoch: 36; Error: 1572.30049665;
Epoch: 39; Error: 1560.65981199;
Epoch: 42; Error: 1545.40917556;
Epoch: 45; Error: 1534.52898091;
Epoch: 48; Error: 1525.45421865;
Epoch: 51; Error: 1510.75469826;
Epoch: 54; Error: 1487.69731472;
Epoch: 57; Error: 1473.96438639;
Epoch: 60; Error: 1463.02429185;
Epoch: 63; Error: 1455.1418991;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1843.53261836;
Epoch: 6; Error: 1761.90100017;
Epoch: 9; Error: 1728.66819589;
Epoch: 12; Error: 1681.27413177;
Epoch: 15; Error: 1656.0354924;
Epoch: 18; Error: 1634.61905608;
Epoch: 21; Error: 1618.80476789;
Epoch: 24; Error: 1607.14442389;
Epoch: 27; Error: 1597.8526771;
Epoch: 30; Error: 1583.8629094;
Epoch: 33; Error: 1578.51363252;
Epoch: 36; Error: 1571.76675712;
Epoch: 39; Error: 1565.30417012;
Epoch: 42; Error: 1559.35816062;
Epoch: 45; Error: 1555.60114617;
Epoch: 48; Error: 1550.75128295;
Epoch: 51; Error: 1546.04949859;
Epoch: 54; Error: 1542.81936767;
Epoch: 57; Error: 1540.40017247;
Epoch: 60; Error: 1537.76736255;
Epoch: 63; Error: 1535.52055641;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1853.82502849;
Epoch: 6; Error: 1773.75784827;
Epoch: 9; Error: 1728.85267862;
Epoch: 12; Error: 1689.1152862;
Epoch: 15; Error: 1664.12061438;
Epoch: 18; Error: 1655.97318365;
Epoch: 21; Error: 1642.31158286;
Epoch: 24; Error: 1632.51319606;
Epoch: 27; Error: 1623.90209165;
Epoch: 30; Error: 1618.76730491;
Epoch: 33; Error: 1615.42911317;
Epoch: 36; Error: 1609.64341208;
Epoch: 39; Error: 1605.37338645;
Epoch: 42; Error: 1602.0326607;
Epoch: 45; Error: 1598.50088711;
Epoch: 48; Error: 1595.63248785;
Epoch: 51; Error: 1592.11378455;
Epoch: 54; Error: 1587.43750187;
Epoch: 57; Error: 1582.23982909;
Epoch: 60; Error: 1578.88778488;
Epoch: 63; Error: 1574.70740847;
The maximum number of train epochs is reached
Best train error: 1451.22673589...
Best Net 5: <neurolab.core.Net object at 0x1093cf3d0>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 7/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 30 35 37 40 41 42 43 44
 51 53]
word_freq_3d: [ 0.01485675]
word_freq_remove: [-0.0500317]
word_freq_order: [ 0.16599242]
word_freq_receive: [ 0.06538125]
word_freq_people: [ 0.05823475]
word_freq_report: [ 0.11902407]
word_freq_addresses: [ 0.08561066]
word_freq_you: [-0.0480856]
word_freq_credit: [ 0.01789168]
word_freq_your: [-0.03920747]
word_freq_font: [ 0.07577156]
word_freq_000: [ 0.04716218]
word_freq_money: [ 0.03485393]
word_freq_hpl: [-0.01238779]
word_freq_george: [-0.06777873]
word_freq_650: [-0.02444741]
word_freq_labs: [-0.02794749]
word_freq_857: [ 0.01587318]
word_freq_1999: [ 0.03659373]
word_freq_pm: [-0.02589164]
word_freq_meeting: [-0.03828849]
word_freq_original: [-0.01754404]
word_freq_project: [-0.02654484]
word_freq_re: [-0.05310406]
word_freq_edu: [-0.03017844]
char_freq_$: [ 0.1144202]
capital_run_length_average: [ 0.12581524]
Cross validation fold 7/10
Train indices: [   0    1    2 ..., 4598 4599 4600]
Test indices: [   3   22   25   65  103  116  129  130  149  151  190  192  227  230  234
  236  255  266  267  270  271  273  306  361  362  371  383  398  407  422
  428  443  445  452  453  454  462  465  474  485  497  499  512  518  524
  561  581  593  609  616  617  629  639  641  644  678  679  687  690  695
  698  699  711  712  721  731  736  753  759  766  769  786  818  850  851
  870  875  880  888  901  904  928  945  956  962  967  968  972  973  976
  986  993  996 1000 1003 1007 1009 1017 1018 1019 1023 1025 1036 1041 1065
 1068 1092 1098 1100 1101 1103 1121 1137 1139 1140 1144 1151 1167 1170 1178
 1180 1182 1218 1245 1264 1295 1320 1322 1326 1328 1343 1353 1354 1363 1365
 1370 1377 1379 1381 1388 1407 1410 1423 1439 1450 1452 1453 1472 1484 1492
 1539 1546 1548 1552 1567 1570 1584 1596 1602 1607 1623 1625 1637 1653 1660
 1668 1670 1695 1697 1703 1704 1711 1719 1728 1735 1736 1742 1743 1746 1757
 1765 1782 1785 1793 1815 1821 1824 1840 1842 1858 1860 1870 1888 1891 1900
 1905 1917 1918 1927 1934 1938 1942 1946 1961 1966 1979 1987 2011 2014 2024
 2039 2040 2068 2073 2106 2110 2119 2120 2129 2148 2149 2153 2175 2188 2203
 2248 2267 2287 2289 2292 2296 2310 2321 2328 2332 2342 2344 2351 2359 2376
 2391 2402 2407 2410 2417 2420 2425 2427 2433 2435 2437 2444 2450 2454 2457
 2465 2483 2486 2510 2514 2522 2528 2538 2541 2552 2567 2575 2582 2595 2621
 2623 2629 2634 2635 2656 2675 2679 2696 2700 2713 2720 2735 2745 2747 2761
 2765 2783 2793 2825 2843 2850 2851 2858 2884 2888 2889 2892 2902 2907 2935
 2943 2966 2967 2973 2977 2982 3003 3008 3014 3022 3026 3039 3045 3049 3051
 3056 3059 3061 3071 3081 3083 3084 3086 3121 3130 3131 3152 3155 3161 3167
 3171 3173 3184 3185 3197 3200 3228 3243 3248 3256 3263 3268 3270 3278 3308
 3324 3326 3332 3350 3372 3373 3374 3386 3398 3402 3405 3425 3442 3446 3465
 3471 3474 3490 3497 3515 3530 3544 3546 3548 3553 3562 3566 3572 3574 3587
 3618 3628 3634 3637 3639 3648 3659 3662 3666 3669 3672 3680 3685 3686 3698
 3704 3721 3749 3751 3756 3765 3767 3775 3806 3837 3869 3879 3925 3935 3960
 3982 3984 3989 3995 4002 4008 4040 4042 4046 4048 4055 4061 4067 4069 4081
 4086 4099 4113 4115 4126 4137 4141 4142 4144 4161 4197 4207 4215 4227 4256
 4259 4263 4265 4266 4321 4334 4351 4384 4391 4407 4410 4444 4462 4477 4478
 4481 4497 4504 4535 4546 4547 4552 4567 4572 4596]
Features no: 27

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1667.60564251;
Epoch: 6; Error: 1573.45438293;
Epoch: 9; Error: 1517.84750972;
Epoch: 12; Error: 1470.96735812;
Epoch: 15; Error: 1436.87280972;
Epoch: 18; Error: 1400.57476726;
Epoch: 21; Error: 1391.39844364;
Epoch: 24; Error: 1373.93534727;
Epoch: 27; Error: 1360.50424214;
Epoch: 30; Error: 1350.23265187;
Epoch: 33; Error: 1342.1826733;
Epoch: 36; Error: 1335.96340191;
Epoch: 39; Error: 1329.23705267;
Epoch: 42; Error: 1323.74826228;
Epoch: 45; Error: 1319.90905448;
Epoch: 48; Error: 1311.79096189;
Epoch: 51; Error: 1304.08160181;
Epoch: 54; Error: 1300.08760768;
Epoch: 57; Error: 1295.46615028;
Epoch: 60; Error: 1293.50594418;
Epoch: 63; Error: 1288.63992838;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1619.29279574;
Epoch: 6; Error: 1470.81603624;
Epoch: 9; Error: 1440.2529953;
Epoch: 12; Error: 1424.07037552;
Epoch: 15; Error: 1409.81051165;
Epoch: 18; Error: 1400.96645366;
Epoch: 21; Error: 1398.47380353;
Epoch: 24; Error: 1394.69920479;
Epoch: 27; Error: 1390.86674238;
Epoch: 30; Error: 1385.77948679;
Epoch: 33; Error: 1383.11696818;
Epoch: 36; Error: 1379.67727273;
Epoch: 39; Error: 1372.55705163;
Epoch: 42; Error: 1367.68136993;
Epoch: 45; Error: 1363.45534458;
Epoch: 48; Error: 1359.28235074;
Epoch: 51; Error: 1356.81183215;
Epoch: 54; Error: 1349.90346785;
Epoch: 57; Error: 1337.39653602;
Epoch: 60; Error: 1334.49589554;
Epoch: 63; Error: 1326.77133089;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1704.17631087;
Epoch: 6; Error: 1602.88046671;
Epoch: 9; Error: 1550.35510052;
Epoch: 12; Error: 1512.88073865;
Epoch: 15; Error: 1465.99695408;
Epoch: 18; Error: 1444.99015128;
Epoch: 21; Error: 1434.96098918;
Epoch: 24; Error: 1427.86729223;
Epoch: 27; Error: 1413.4909991;
Epoch: 30; Error: 1399.66764201;
Epoch: 33; Error: 1388.29771308;
Epoch: 36; Error: 1378.11557987;
Epoch: 39; Error: 1368.23692116;
Epoch: 42; Error: 1360.07200137;
Epoch: 45; Error: 1352.98234849;
Epoch: 48; Error: 1347.72939871;
Epoch: 51; Error: 1344.2127248;
Epoch: 54; Error: 1341.49613381;
Epoch: 57; Error: 1337.94289562;
Epoch: 60; Error: 1335.54441732;
Epoch: 63; Error: 1332.4223006;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1547.17565009;
Epoch: 6; Error: 1507.05431749;
Epoch: 9; Error: 1463.52315584;
Epoch: 12; Error: 1436.46189397;
Epoch: 15; Error: 1417.02568554;
Epoch: 18; Error: 1401.79856261;
Epoch: 21; Error: 1392.52355529;
Epoch: 24; Error: 1380.97060956;
Epoch: 27; Error: 1367.62495653;
Epoch: 30; Error: 1360.35699569;
Epoch: 33; Error: 1356.8668122;
Epoch: 36; Error: 1354.81632989;
Epoch: 39; Error: 1351.41542752;
Epoch: 42; Error: 1345.62031053;
Epoch: 45; Error: 1341.79967177;
Epoch: 48; Error: 1337.57545369;
Epoch: 51; Error: 1335.04680843;
Epoch: 54; Error: 1332.94185186;
Epoch: 57; Error: 1329.10188309;
Epoch: 60; Error: 1326.29312546;
Epoch: 63; Error: 1324.15938152;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1696.18950373;
Epoch: 6; Error: 1498.23484643;
Epoch: 9; Error: 1445.40471525;
Epoch: 12; Error: 1426.43448464;
Epoch: 15; Error: 1411.23584562;
Epoch: 18; Error: 1384.95902637;
Epoch: 21; Error: 1378.94208519;
Epoch: 24; Error: 1370.21805169;
Epoch: 27; Error: 1355.23358738;
Epoch: 30; Error: 1350.39743778;
Epoch: 33; Error: 1341.68012964;
Epoch: 36; Error: 1334.45852986;
Epoch: 39; Error: 1326.78322118;
Epoch: 42; Error: 1320.27423788;
Epoch: 45; Error: 1313.10429025;
Epoch: 48; Error: 1307.64143333;
Epoch: 51; Error: 1303.87611165;
Epoch: 54; Error: 1298.87772516;
Epoch: 57; Error: 1291.96428174;
Epoch: 60; Error: 1287.2740616;
Epoch: 63; Error: 1279.33036968;
The maximum number of train epochs is reached
Best train error: 1277.79513793...
Best Net 6: <neurolab.core.Net object at 0x10ce82ad0>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 8/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 30 33 35 37 40 41 42 43
 44 51 53]
word_freq_3d: [ 0.0127849]
word_freq_remove: [-0.04731614]
word_freq_order: [ 0.16431434]
word_freq_receive: [ 0.06985049]
word_freq_people: [ 0.05155258]
word_freq_report: [ 0.142001]
word_freq_addresses: [ 0.06342698]
word_freq_you: [-0.05690996]
word_freq_credit: [ 0.02075112]
word_freq_your: [-0.0442645]
word_freq_font: [ 0.10298523]
word_freq_000: [ 0.05913729]
word_freq_money: [ 0.044152]
word_freq_hpl: [-0.01929559]
word_freq_george: [-0.07062749]
word_freq_650: [-0.03702591]
word_freq_labs: [-0.03465906]
word_freq_857: [ 0.01501802]
word_freq_85: [ 0.02773554]
word_freq_1999: [ 0.04622489]
word_freq_pm: [-0.02563044]
word_freq_meeting: [-0.03915363]
word_freq_original: [-0.02238085]
word_freq_project: [-0.02665779]
word_freq_re: [-0.05102212]
word_freq_edu: [-0.02611401]
char_freq_$: [ 0.10563244]
capital_run_length_average: [ 0.12569533]
Cross validation fold 8/10
Train indices: [   0    1    2 ..., 4597 4598 4600]
Test indices: [   6   27   30   40   57   61   64   69   75   77   83   91   96   97  101
  106  108  109  118  124  128  131  141  158  160  170  182  188  196  211
  212  213  217  218  225  228  231  237  239  252  291  303  304  310  316
  325  334  341  344  373  378  381  386  395  408  409  413  415  447  450
  460  477  481  495  515  521  550  566  584  598  600  622  628  630  656
  664  669  674  686  688  691  693  703  710  723  735  740  744  747  754
  762  764  770  779  793  805  810  811  813  835  846  858  865  874  881
  884  893  895  899  900  912  915  916  951  958  965 1004 1005 1013 1029
 1038 1051 1085 1089 1094 1096 1126 1130 1133 1143 1149 1164 1171 1185 1193
 1196 1203 1217 1234 1235 1257 1263 1273 1286 1287 1289 1297 1299 1302 1334
 1342 1345 1346 1349 1351 1358 1361 1366 1369 1396 1406 1430 1434 1448 1462
 1468 1470 1473 1474 1490 1502 1517 1522 1523 1525 1526 1528 1538 1540 1544
 1550 1558 1587 1621 1632 1641 1673 1686 1696 1699 1721 1722 1727 1737 1767
 1768 1783 1788 1792 1794 1816 1820 1825 1841 1844 1859 1867 1875 1876 1878
 1885 1915 1916 1923 1926 1943 1967 1977 1981 2008 2020 2047 2058 2069 2087
 2113 2137 2139 2154 2164 2165 2182 2193 2197 2209 2223 2237 2241 2242 2263
 2278 2302 2307 2309 2313 2314 2316 2330 2333 2337 2346 2358 2378 2392 2414
 2418 2419 2440 2441 2460 2464 2470 2482 2488 2500 2511 2513 2561 2598 2599
 2602 2631 2642 2664 2668 2670 2681 2726 2734 2738 2742 2753 2754 2756 2759
 2767 2772 2806 2818 2827 2829 2831 2836 2855 2863 2871 2880 2881 2886 2904
 2908 2911 2920 2931 2932 2936 2937 2942 2948 2971 2988 2999 3005 3052 3054
 3066 3102 3118 3119 3125 3127 3133 3142 3160 3163 3164 3165 3172 3174 3191
 3208 3211 3226 3236 3260 3291 3292 3296 3297 3298 3304 3309 3315 3316 3322
 3323 3330 3333 3339 3344 3345 3348 3366 3412 3427 3440 3450 3459 3501 3502
 3524 3526 3578 3579 3581 3586 3596 3600 3609 3610 3616 3638 3647 3656 3668
 3673 3691 3692 3696 3700 3714 3722 3728 3735 3736 3741 3747 3754 3763 3769
 3778 3790 3802 3821 3823 3832 3834 3846 3852 3870 3872 3877 3880 3904 3913
 3915 3927 3928 3929 3952 3970 4006 4021 4032 4047 4072 4075 4082 4095 4100
 4102 4120 4136 4146 4147 4150 4179 4181 4186 4190 4201 4218 4219 4231 4233
 4237 4267 4268 4290 4293 4313 4319 4328 4332 4338 4357 4376 4383 4399 4430
 4433 4451 4458 4512 4533 4548 4554 4570 4583 4599]
Features no: 28

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1956.02455826;
Epoch: 6; Error: 1823.95987545;
Epoch: 9; Error: 1772.96759648;
Epoch: 12; Error: 1750.83070115;
Epoch: 15; Error: 1717.66919765;
Epoch: 18; Error: 1696.51668559;
Epoch: 21; Error: 1682.17847529;
Epoch: 24; Error: 1662.81582487;
Epoch: 27; Error: 1651.49093916;
Epoch: 30; Error: 1635.72732086;
Epoch: 33; Error: 1629.56174857;
Epoch: 36; Error: 1622.25571146;
Epoch: 39; Error: 1613.44300126;
Epoch: 42; Error: 1608.45570279;
Epoch: 45; Error: 1602.02090636;
Epoch: 48; Error: 1594.66576796;
Epoch: 51; Error: 1587.69165341;
Epoch: 54; Error: 1583.58602167;
Epoch: 57; Error: 1579.85703005;
Epoch: 60; Error: 1577.5530476;
Epoch: 63; Error: 1575.4088962;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1852.1348159;
Epoch: 6; Error: 1813.88755271;
Epoch: 9; Error: 1745.876767;
Epoch: 12; Error: 1705.01330306;
Epoch: 15; Error: 1677.58956463;
Epoch: 18; Error: 1653.16944124;
Epoch: 21; Error: 1637.76199091;
Epoch: 24; Error: 1623.79054143;
Epoch: 27; Error: 1616.82299497;
Epoch: 30; Error: 1611.88762392;
Epoch: 33; Error: 1604.18235039;
Epoch: 36; Error: 1600.02072978;
Epoch: 39; Error: 1596.86576903;
Epoch: 42; Error: 1592.68837104;
Epoch: 45; Error: 1589.51427066;
Epoch: 48; Error: 1586.48979905;
Epoch: 51; Error: 1583.04314804;
Epoch: 54; Error: 1580.11841925;
Epoch: 57; Error: 1575.96107072;
Epoch: 60; Error: 1573.21998112;
Epoch: 63; Error: 1571.08948335;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 2022.3121664;
Epoch: 6; Error: 1897.19344074;
Epoch: 9; Error: 1833.44768301;
Epoch: 12; Error: 1806.03214698;
Epoch: 15; Error: 1770.5765678;
Epoch: 18; Error: 1728.69308328;
Epoch: 21; Error: 1701.50067187;
Epoch: 24; Error: 1679.64074597;
Epoch: 27; Error: 1669.47488575;
Epoch: 30; Error: 1652.57368811;
Epoch: 33; Error: 1645.73123256;
Epoch: 36; Error: 1636.75715663;
Epoch: 39; Error: 1632.58677867;
Epoch: 42; Error: 1625.68415211;
Epoch: 45; Error: 1617.60563931;
Epoch: 48; Error: 1611.59328236;
Epoch: 51; Error: 1603.9472273;
Epoch: 54; Error: 1597.35855915;
Epoch: 57; Error: 1591.45946994;
Epoch: 60; Error: 1580.34765122;
Epoch: 63; Error: 1574.5656065;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1997.39664875;
Epoch: 6; Error: 1879.49881024;
Epoch: 9; Error: 1791.69796392;
Epoch: 12; Error: 1764.33007766;
Epoch: 15; Error: 1735.37598428;
Epoch: 18; Error: 1677.24659711;
Epoch: 21; Error: 1649.90713909;
Epoch: 24; Error: 1620.96197803;
Epoch: 27; Error: 1600.11636985;
Epoch: 30; Error: 1590.66235836;
Epoch: 33; Error: 1575.38912547;
Epoch: 36; Error: 1562.96257193;
Epoch: 39; Error: 1555.22789707;
Epoch: 42; Error: 1547.06905583;
Epoch: 45; Error: 1540.83119834;
Epoch: 48; Error: 1526.71108859;
Epoch: 51; Error: 1516.13474489;
Epoch: 54; Error: 1503.92690069;
Epoch: 57; Error: 1498.61649427;
Epoch: 60; Error: 1489.02260514;
Epoch: 63; Error: 1481.15204045;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 2022.06588153;
Epoch: 6; Error: 1931.46120217;
Epoch: 9; Error: 1858.1227141;
Epoch: 12; Error: 1804.91367207;
Epoch: 15; Error: 1779.94415932;
Epoch: 18; Error: 1756.40149293;
Epoch: 21; Error: 1734.05221158;
Epoch: 24; Error: 1707.23897857;
Epoch: 27; Error: 1694.43367627;
Epoch: 30; Error: 1675.03616831;
Epoch: 33; Error: 1646.78123654;
Epoch: 36; Error: 1623.65305619;
Epoch: 39; Error: 1610.19484899;
Epoch: 42; Error: 1593.02719946;
Epoch: 45; Error: 1580.65621701;
Epoch: 48; Error: 1569.47627396;
Epoch: 51; Error: 1553.93763577;
Epoch: 54; Error: 1538.38137873;
Epoch: 57; Error: 1527.4833389;
Epoch: 60; Error: 1520.29233401;
Epoch: 63; Error: 1515.06512835;
The maximum number of train epochs is reached
Best train error: 1479.59873235...
Best Net 7: <neurolab.core.Net object at 0x10c899c50>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 9/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 16 17 18 19 20 21 22 24 25 26 28 30 35 37 40 41 42 43
 44 50 51 53]
word_freq_3d: [ 0.0115953]
word_freq_remove: [-0.05835984]
word_freq_order: [ 0.15232127]
word_freq_receive: [ 0.07983823]
word_freq_people: [ 0.0434501]
word_freq_report: [ 0.18004796]
word_freq_addresses: [ 0.07131018]
word_freq_email: [ 0.01034354]
word_freq_you: [-0.05223834]
word_freq_credit: [ 0.01750598]
word_freq_your: [-0.04664035]
word_freq_font: [ 0.1024307]
word_freq_000: [ 0.06339841]
word_freq_money: [ 0.0565856]
word_freq_hpl: [-0.01340359]
word_freq_george: [-0.06855231]
word_freq_650: [-0.02714461]
word_freq_labs: [-0.02979222]
word_freq_857: [ 0.01947105]
word_freq_1999: [ 0.0468955]
word_freq_pm: [-0.02035291]
word_freq_meeting: [-0.03741647]
word_freq_original: [-0.02419592]
word_freq_project: [-0.02593453]
word_freq_re: [-0.06058742]
word_freq_edu: [-0.03028222]
char_freq_!: [ 0.00514842]
char_freq_$: [ 0.09510174]
capital_run_length_average: [ 0.1243801]
Cross validation fold 9/10
Train indices: [   0    1    2 ..., 4598 4599 4600]
Test indices: [   7   11   12   13   20   21   24   45   47   53   56   59   78   86   92
   93   94  122  126  135  142  145  155  173  174  177  179  206  214  215
  221  223  226  235  245  257  260  265  280  290  297  319  329  335  337
  339  365  375  382  394  405  439  441  446  455  457  466  483  491  504
  509  527  538  545  552  557  589  590  601  604  607  608  613  621  624
  625  636  643  647  650  661  671  700  708  716  718  729  756  777  799
  817  826  866  871  891  898  906  938  948  959  961  969  978  980  981
  984  992 1020 1035 1037 1049 1053 1056 1059 1069 1077 1079 1086 1105 1106
 1117 1131 1134 1150 1153 1160 1161 1188 1199 1224 1240 1242 1259 1262 1288
 1291 1296 1317 1347 1371 1375 1385 1418 1428 1435 1437 1441 1446 1454 1464
 1489 1509 1519 1533 1536 1554 1564 1566 1577 1583 1585 1600 1601 1606 1614
 1619 1627 1628 1630 1647 1648 1663 1682 1685 1688 1693 1702 1707 1724 1729
 1733 1739 1740 1745 1751 1781 1787 1790 1813 1829 1839 1864 1877 1893 1894
 1899 1902 1909 1922 1924 1935 1937 1939 1947 1948 1959 1965 1971 1978 1984
 1990 2000 2009 2015 2019 2025 2032 2033 2049 2050 2104 2107 2121 2128 2133
 2172 2177 2196 2210 2211 2219 2220 2240 2246 2262 2269 2272 2303 2320 2324
 2334 2336 2341 2347 2356 2357 2362 2365 2374 2379 2411 2424 2474 2492 2495
 2496 2527 2532 2533 2547 2557 2562 2603 2611 2645 2652 2654 2661 2665 2667
 2673 2683 2684 2708 2715 2740 2750 2755 2766 2777 2790 2797 2821 2822 2859
 2878 2894 2899 2934 2945 2956 2963 2991 3012 3013 3027 3030 3031 3034 3036
 3046 3050 3060 3067 3070 3077 3087 3095 3099 3109 3111 3116 3137 3140 3182
 3187 3188 3202 3209 3234 3235 3239 3242 3251 3274 3276 3277 3305 3314 3329
 3334 3335 3355 3356 3358 3359 3365 3375 3388 3392 3403 3407 3441 3448 3449
 3454 3463 3473 3479 3480 3493 3527 3532 3545 3567 3568 3577 3589 3607 3642
 3660 3665 3676 3677 3702 3723 3730 3738 3750 3772 3781 3782 3784 3786 3811
 3819 3825 3839 3841 3849 3858 3862 3874 3881 3884 3906 3910 3919 3931 3933
 3936 3966 3976 3981 3986 3993 4009 4035 4043 4044 4049 4057 4071 4077 4085
 4090 4105 4109 4111 4127 4156 4167 4196 4198 4204 4206 4216 4246 4274 4275
 4287 4294 4295 4296 4305 4318 4320 4355 4362 4364 4373 4393 4402 4409 4412
 4421 4422 4427 4434 4436 4439 4440 4445 4453 4455 4461 4472 4473 4483 4494
 4495 4499 4510 4517 4537 4539 4543 4556 4579 4582]
Features no: 29

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1822.75184951;
Epoch: 6; Error: 1717.91784439;
Epoch: 9; Error: 1670.35481309;
Epoch: 12; Error: 1618.62917585;
Epoch: 15; Error: 1588.82009541;
Epoch: 18; Error: 1557.64420064;
Epoch: 21; Error: 1543.17324972;
Epoch: 24; Error: 1537.37597454;
Epoch: 27; Error: 1530.09308356;
Epoch: 30; Error: 1523.44487742;
Epoch: 33; Error: 1514.47833398;
Epoch: 36; Error: 1507.95952657;
Epoch: 39; Error: 1499.53082343;
Epoch: 42; Error: 1492.55417258;
Epoch: 45; Error: 1486.21012381;
Epoch: 48; Error: 1481.898326;
Epoch: 51; Error: 1478.69758649;
Epoch: 54; Error: 1474.08147892;
Epoch: 57; Error: 1469.32753961;
Epoch: 60; Error: 1466.20245938;
Epoch: 63; Error: 1463.76084849;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1821.48643557;
Epoch: 6; Error: 1770.42595528;
Epoch: 9; Error: 1725.08716334;
Epoch: 12; Error: 1703.05664834;
Epoch: 15; Error: 1672.17048192;
Epoch: 18; Error: 1652.8206249;
Epoch: 21; Error: 1633.40451748;
Epoch: 24; Error: 1624.18988808;
Epoch: 27; Error: 1607.35506783;
Epoch: 30; Error: 1595.1956551;
Epoch: 33; Error: 1584.64734272;
Epoch: 36; Error: 1569.24570949;
Epoch: 39; Error: 1552.90076209;
Epoch: 42; Error: 1531.1692769;
Epoch: 45; Error: 1518.17294242;
Epoch: 48; Error: 1494.45135691;
Epoch: 51; Error: 1482.1312953;
Epoch: 54; Error: 1471.7570695;
Epoch: 57; Error: 1458.38541062;
Epoch: 60; Error: 1445.55836233;
Epoch: 63; Error: 1434.99627032;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1812.50819932;
Epoch: 6; Error: 1735.52816651;
Epoch: 9; Error: 1702.03878575;
Epoch: 12; Error: 1676.18043562;
Epoch: 15; Error: 1659.90742531;
Epoch: 18; Error: 1639.69129655;
Epoch: 21; Error: 1627.16643013;
Epoch: 24; Error: 1606.58705034;
Epoch: 27; Error: 1595.88960702;
Epoch: 30; Error: 1582.29349591;
Epoch: 33; Error: 1570.88518713;
Epoch: 36; Error: 1562.53907014;
Epoch: 39; Error: 1554.92351697;
Epoch: 42; Error: 1546.49564826;
Epoch: 45; Error: 1539.24606533;
Epoch: 48; Error: 1533.05598376;
Epoch: 51; Error: 1527.368061;
Epoch: 54; Error: 1520.28858931;
Epoch: 57; Error: 1513.14855719;
Epoch: 60; Error: 1505.16034161;
Epoch: 63; Error: 1499.97926753;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 1916.71680859;
Epoch: 6; Error: 1744.75041508;
Epoch: 9; Error: 1672.32045244;
Epoch: 12; Error: 1632.09333265;
Epoch: 15; Error: 1614.88275204;
Epoch: 18; Error: 1603.38116594;
Epoch: 21; Error: 1590.9111289;
Epoch: 24; Error: 1582.53714802;
Epoch: 27; Error: 1570.32920239;
Epoch: 30; Error: 1564.98809186;
Epoch: 33; Error: 1553.66813236;
Epoch: 36; Error: 1548.38598168;
Epoch: 39; Error: 1541.44810187;
Epoch: 42; Error: 1533.80927084;
Epoch: 45; Error: 1526.22402707;
Epoch: 48; Error: 1519.50172779;
Epoch: 51; Error: 1516.33425261;
Epoch: 54; Error: 1510.58574472;
Epoch: 57; Error: 1507.24058772;
Epoch: 60; Error: 1502.83401302;
Epoch: 63; Error: 1500.84577672;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1868.58034517;
Epoch: 6; Error: 1749.81868015;
Epoch: 9; Error: 1705.89118484;
Epoch: 12; Error: 1663.47287678;
Epoch: 15; Error: 1634.14052788;
Epoch: 18; Error: 1595.62703016;
Epoch: 21; Error: 1578.78066762;
Epoch: 24; Error: 1554.0659847;
Epoch: 27; Error: 1544.61436403;
Epoch: 30; Error: 1529.14839428;
Epoch: 33; Error: 1514.61195725;
Epoch: 36; Error: 1503.63879894;
Epoch: 39; Error: 1492.98598815;
Epoch: 42; Error: 1487.24414036;
Epoch: 45; Error: 1476.72942534;
Epoch: 48; Error: 1463.30400346;
Epoch: 51; Error: 1457.68308947;
Epoch: 54; Error: 1449.44154762;
Epoch: 57; Error: 1441.15293013;
Epoch: 60; Error: 1432.84440553;
Epoch: 63; Error: 1425.11084148;
The maximum number of train epochs is reached
Best train error: 1421.9413869...
Best Net 8: <neurolab.core.Net object at 0x10c9d4b10>
--------------STOP ANN ON FOLD--------------

Crossvalidation fold: 10/10
--------------START LINEAR ON FOLD--------------
MODEL COEFFICENTS: 
Selected Features: [ 2  5  7  9 11 12 13 17 18 19 20 21 22 24 25 26 28 30 35 37 40 41 42 43 44
 51 53]
word_freq_3d: [ 0.00689388]
word_freq_remove: [-0.05189366]
word_freq_order: [ 0.16971404]
word_freq_receive: [ 0.06606249]
word_freq_people: [ 0.05359396]
word_freq_report: [ 0.12692896]
word_freq_addresses: [ 0.06479205]
word_freq_you: [-0.05170948]
word_freq_credit: [ 0.01743045]
word_freq_your: [-0.0463832]
word_freq_font: [ 0.10282471]
word_freq_000: [ 0.05129523]
word_freq_money: [ 0.03745141]
word_freq_hpl: [-0.01895157]
word_freq_george: [-0.06980303]
word_freq_650: [-0.02765476]
word_freq_labs: [-0.03253546]
word_freq_857: [ 0.02156261]
word_freq_1999: [ 0.03873031]
word_freq_pm: [-0.02447841]
word_freq_meeting: [-0.0371604]
word_freq_original: [-0.01822303]
word_freq_project: [-0.02589949]
word_freq_re: [-0.05371097]
word_freq_edu: [-0.02800611]
char_freq_$: [ 0.12146869]
capital_run_length_average: [ 0.12147069]
Cross validation fold 10/10
Train indices: [   0    1    2 ..., 4598 4599 4600]
Test indices: [   4   18   19   32   37   38   67  102  104  105  114  120  133  152  162
  167  199  200  201  203  207  209  216  251  256  264  274  278  282  284
  285  293  326  331  332  336  347  369  390  403  410  429  432  434  442
  444  451  468  471  500  501  502  507  511  522  534  541  546  562  574
  594  595  610  627  642  660  682  683  685  694  705  719  724  733  737
  738  742  767  772  783  785  790  796  802  803  823  824  827  842  847
  853  859  878  886  887  923  930  936  937  940  974  982  991  999 1012
 1021 1050 1052 1054 1088 1102 1111 1128 1138 1142 1145 1172 1174 1177 1211
 1222 1225 1228 1244 1255 1260 1261 1292 1294 1304 1313 1324 1330 1335 1344
 1352 1408 1409 1416 1420 1429 1443 1451 1465 1471 1482 1491 1496 1498 1535
 1542 1556 1560 1561 1572 1574 1578 1582 1608 1613 1617 1618 1620 1622 1624
 1657 1662 1674 1687 1692 1701 1723 1726 1731 1732 1748 1759 1762 1780 1789
 1798 1811 1827 1892 1911 1928 1932 1949 1973 1983 1985 1996 1998 2003 2023
 2031 2044 2046 2051 2057 2065 2074 2092 2101 2112 2127 2140 2142 2145 2147
 2150 2157 2159 2166 2168 2170 2179 2190 2192 2204 2205 2212 2213 2217 2235
 2254 2256 2266 2271 2281 2283 2297 2308 2318 2340 2348 2366 2367 2373 2375
 2385 2398 2421 2422 2463 2473 2477 2481 2484 2487 2493 2507 2516 2523 2526
 2529 2548 2560 2571 2591 2606 2610 2632 2660 2687 2689 2703 2706 2710 2717
 2721 2728 2729 2743 2773 2787 2788 2839 2841 2842 2868 2875 2879 2882 2896
 2898 2905 2914 2919 2923 2929 2947 2955 2961 2964 2976 2979 2983 2992 2993
 2994 2995 3016 3062 3088 3090 3110 3122 3144 3157 3166 3175 3181 3186 3192
 3193 3195 3199 3212 3217 3218 3229 3238 3250 3253 3275 3283 3289 3303 3320
 3321 3347 3364 3382 3385 3393 3397 3413 3419 3426 3434 3435 3457 3462 3478
 3483 3484 3509 3519 3525 3535 3537 3551 3570 3580 3588 3592 3602 3608 3623
 3652 3657 3679 3684 3734 3739 3745 3746 3762 3768 3771 3791 3797 3799 3809
 3818 3824 3830 3860 3866 3876 3890 3894 3901 3909 3930 3947 3949 3950 3957
 3961 3964 3967 3987 3991 4007 4013 4029 4033 4039 4045 4052 4098 4110 4123
 4130 4158 4164 4165 4172 4183 4187 4199 4223 4225 4229 4232 4238 4247 4252
 4257 4260 4271 4286 4291 4292 4298 4299 4303 4309 4310 4311 4325 4330 4331
 4335 4343 4349 4366 4372 4388 4389 4405 4415 4426 4432 4437 4446 4447 4467
 4480 4491 4493 4518 4531 4560 4561 4575 4578 4594]
Features no: 27

--------------STOP LINEAR ON FOLD--------------
--------------START ANN ON FOLD--------------
Training network 1/5...
Epoch: 3; Error: 1949.00423181;
Epoch: 6; Error: 1824.84785625;
Epoch: 9; Error: 1758.91255699;
Epoch: 12; Error: 1741.44233661;
Epoch: 15; Error: 1713.0746504;
Epoch: 18; Error: 1693.63082546;
Epoch: 21; Error: 1666.89139804;
Epoch: 24; Error: 1645.83235451;
Epoch: 27; Error: 1623.18214511;
Epoch: 30; Error: 1611.58224088;
Epoch: 33; Error: 1600.38944772;
Epoch: 36; Error: 1589.01181653;
Epoch: 39; Error: 1576.85401315;
Epoch: 42; Error: 1556.56490842;
Epoch: 45; Error: 1548.02715159;
Epoch: 48; Error: 1536.10092134;
Epoch: 51; Error: 1525.63957673;
Epoch: 54; Error: 1518.44304255;
Epoch: 57; Error: 1509.1934746;
Epoch: 60; Error: 1502.63854367;
Epoch: 63; Error: 1495.94920094;
The maximum number of train epochs is reached
Training network 2/5...
Epoch: 3; Error: 1970.52483454;
Epoch: 6; Error: 1827.90557194;
Epoch: 9; Error: 1770.97522297;
Epoch: 12; Error: 1738.41165628;
Epoch: 15; Error: 1722.40942608;
Epoch: 18; Error: 1697.79141912;
Epoch: 21; Error: 1672.87621684;
Epoch: 24; Error: 1667.50042763;
Epoch: 27; Error: 1659.78671173;
Epoch: 30; Error: 1645.8369821;
Epoch: 33; Error: 1634.30864256;
Epoch: 36; Error: 1618.17989774;
Epoch: 39; Error: 1588.19835026;
Epoch: 42; Error: 1578.74205346;
Epoch: 45; Error: 1569.11945264;
Epoch: 48; Error: 1550.2947075;
Epoch: 51; Error: 1529.46507296;
Epoch: 54; Error: 1521.20586926;
Epoch: 57; Error: 1513.59629039;
Epoch: 60; Error: 1508.48834686;
Epoch: 63; Error: 1502.11501938;
The maximum number of train epochs is reached
Training network 3/5...
Epoch: 3; Error: 1890.69633284;
Epoch: 6; Error: 1789.03631816;
Epoch: 9; Error: 1738.74372999;
Epoch: 12; Error: 1701.37482621;
Epoch: 15; Error: 1690.48853597;
Epoch: 18; Error: 1676.93412608;
Epoch: 21; Error: 1655.72667321;
Epoch: 24; Error: 1646.27427203;
Epoch: 27; Error: 1628.2400152;
Epoch: 30; Error: 1612.11103279;
Epoch: 33; Error: 1608.92502799;
Epoch: 36; Error: 1605.34096535;
Epoch: 39; Error: 1598.72738792;
Epoch: 42; Error: 1588.24492456;
Epoch: 45; Error: 1582.84287909;
Epoch: 48; Error: 1576.61052953;
Epoch: 51; Error: 1570.75706801;
Epoch: 54; Error: 1567.47125659;
Epoch: 57; Error: 1564.30478378;
Epoch: 60; Error: 1558.17067605;
Epoch: 63; Error: 1554.88311547;
The maximum number of train epochs is reached
Training network 4/5...
Epoch: 3; Error: 2041.76429343;
Epoch: 6; Error: 1914.0823559;
Epoch: 9; Error: 1849.3405828;
Epoch: 12; Error: 1774.16972309;
Epoch: 15; Error: 1719.94876122;
Epoch: 18; Error: 1673.04050727;
Epoch: 21; Error: 1646.8014874;
Epoch: 24; Error: 1638.18551931;
Epoch: 27; Error: 1616.15646022;
Epoch: 30; Error: 1601.2299575;
Epoch: 33; Error: 1590.36232733;
Epoch: 36; Error: 1574.92276973;
Epoch: 39; Error: 1565.19095754;
Epoch: 42; Error: 1554.54219702;
Epoch: 45; Error: 1544.61436655;
Epoch: 48; Error: 1533.30795945;
Epoch: 51; Error: 1525.38394018;
Epoch: 54; Error: 1517.16266469;
Epoch: 57; Error: 1506.22478561;
Epoch: 60; Error: 1500.17707467;
Epoch: 63; Error: 1489.89711033;
The maximum number of train epochs is reached
Training network 5/5...
Epoch: 3; Error: 1845.76983477;
Epoch: 6; Error: 1776.06204682;
Epoch: 9; Error: 1712.19066951;
Epoch: 12; Error: 1677.33177252;
Epoch: 15; Error: 1655.26900413;
Epoch: 18; Error: 1634.98077013;
Epoch: 21; Error: 1619.903691;
Epoch: 24; Error: 1613.31687377;
Epoch: 27; Error: 1601.99773478;
Epoch: 30; Error: 1582.78864428;
Epoch: 33; Error: 1569.78812916;
Epoch: 36; Error: 1561.55765765;
Epoch: 39; Error: 1556.80481521;
Epoch: 42; Error: 1550.76828872;
Epoch: 45; Error: 1546.75391565;
Epoch: 48; Error: 1541.09721916;
Epoch: 51; Error: 1531.76595978;
Epoch: 54; Error: 1522.99095622;
Epoch: 57; Error: 1514.4096685;
Epoch: 60; Error: 1509.93500344;
Epoch: 63; Error: 1503.58601621;
The maximum number of train epochs is reached
Best train error: 1487.51586367...
Best Net 9: <neurolab.core.Net object at 0x10c953990>
--------------STOP ANN ON FOLD--------------
-------------- START LINEAR CONCLUSION --------------


Linear regression without feature selection:

- Training error: 0.802166799681
- Test error:     0.847338249903
- R^2 train:     0.197802544876
- R^2 test:     0.150031058948
Linear regression with feature selection:

- Training error: 0.822988208962
- Test error:     0.841762266582
- R^2 train:     0.176980339888
- R^2 test:     0.155624353761
Linear Model Parameters: {'copy_X': True, 'normalize': False, 'n_jobs': 1, 'fit_intercept': True}
-------------- STOP LINEAR CONCLUSION --------------
-------------- START ANN CONCLUSION --------------
ANN Mean-square error: 0.764983421612
-------------- STOP ANN CONCLUSION --------------
-------------- START AVERAGE TEST ----------------
-------------- STOP AVERAGE TEST ----------------
-------------- START PAIRED T-TEST ----------------
t-value and p-value
Linear Error Test with FS: [[ 1.4332299 ]
 [ 1.74749452]
 [ 0.40589238]
 [ 0.55372623]
 [ 0.5683    ]
 [ 0.46214522]
 [ 1.69417236]
 [ 0.42056094]
 [ 0.73574744]
 [ 0.39635367]]
ANN Errors: [ 1.25530129  1.72391454  0.34606335  0.45478524  0.49555388  0.42671814
  1.48504843  0.49955183  0.59647154  0.36642598]
Ttest_relResult(statistic=array([-2.35480135, -5.02320999,  2.82264167,  2.20355026,  1.97140278,
        2.36337182, -3.66304276,  1.94863737,  1.39675072,  2.70669141]), pvalue=array([ 0.04296578,  0.00071595,  0.01996073,  0.05502107,  0.08016103,
        0.04236665,  0.00521083,  0.08314846,  0.19597212,  0.02412786]))
-------------- STOP PAIRED T-TEST ----------------
